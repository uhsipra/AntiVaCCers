{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Collected_data_model_testing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOH0TyvEQcgHVn0HkA+9RwW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uhsipra/AntiVaCCers/blob/main/Collected_data_model_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# utilities\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# plotting\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "# nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "# sklearn\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "UdKmQvUbXvjV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "1i8fKYNRXOI6",
        "outputId": "275869e7-cff8-4e0f-92e8-55a0dbe41f34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2eab11c9-06e3-4a8d-9bcf-4ad6a4e8b60b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>RT @ABBedClosures: Multiple DMs over the past ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>RT @MerlinofCanada: There are now 822 COVID-19...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>RT @MerlinofCanada: There are now 822 COVID-19...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>RT @MerlinofCanada: There are now 822 COVID-19...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>@CyrilF24 @JBG_1979 I trust bitchute more than...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2eab11c9-06e3-4a8d-9bcf-4ad6a4e8b60b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2eab11c9-06e3-4a8d-9bcf-4ad6a4e8b60b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2eab11c9-06e3-4a8d-9bcf-4ad6a4e8b60b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                 text\n",
              "56  RT @ABBedClosures: Multiple DMs over the past ...\n",
              "24  RT @MerlinofCanada: There are now 822 COVID-19...\n",
              "51  RT @MerlinofCanada: There are now 822 COVID-19...\n",
              "63  RT @MerlinofCanada: There are now 822 COVID-19...\n",
              "34  @CyrilF24 @JBG_1979 I trust bitchute more than..."
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Loading in collected data for each city\n",
        "dataset_calgary = pd.read_pickle('Calgary.pkl')\n",
        "dataset_edmonton = pd.read_pickle('Edmonton.pkl')\n",
        "dataset_montreal = pd.read_pickle('Montreal.pkl')\n",
        "dataset_ottawa = ppd.read_pickle('Ottoawa.pkl')\n",
        "dataset_edmonton.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to clean up the data by removing stopwords, emojis and converted to lowercase\n",
        "\n",
        "# We will focus on only the text of the tweets and the sentiment (target)\n",
        "dataset = dataset_edmonton\n",
        "\n",
        "\n",
        "# Turning all tweets into lowercase\n",
        "dataset['text'] = dataset['text'].str.lower()\n",
        "dataset['text'].tail()\n",
        "len(dataset['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CE_liH0gXwfu",
        "outputId": "a1f97ca1-eaf3-456d-911a-0c78a8ba6944"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a stopwords set\n",
        "stopwordlist = ['a', 'about', 'above', 'after', 'again', 'ain', 'all', 'am', 'an',\n",
        "             'and','any','are', 'as', 'at', 'be', 'because', 'been', 'before',\n",
        "             'being', 'below', 'between','both', 'by', 'can', 'd', 'did', 'do',\n",
        "             'does', 'doing', 'down', 'during', 'each','few', 'for', 'from',\n",
        "             'further', 'had', 'has', 'have', 'having', 'he', 'her', 'here',\n",
        "             'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in',\n",
        "             'into','is', 'it', 'its', 'itself', 'just', 'll', 'm', 'ma',\n",
        "             'me', 'more', 'most','my', 'myself', 'now', 'o', 'of', 'on', 'once',\n",
        "             'only', 'or', 'other', 'our', 'ours','ourselves', 'out', 'own', 're','s', 'same', 'she', \"shes\", 'should', \"shouldve\",'so', 'some', 'such',\n",
        "             't', 'than', 'that', \"thatll\", 'the', 'their', 'theirs', 'them',\n",
        "             'themselves', 'then', 'there', 'these', 'they', 'this', 'those',\n",
        "             'through', 'to', 'too','under', 'until', 'up', 've', 'very', 'was',\n",
        "             'we', 'were', 'what', 'when', 'where','which','while', 'who', 'whom',\n",
        "             'why', 'will', 'with', 'won', 'y', 'you', \"youd\",\"youll\", \"youre\",\n",
        "             \"youve\", 'your', 'yours', 'yourself', 'yourselves']"
      ],
      "metadata": {
        "id": "7BL49HAdX5Sv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing the stop words from tweet text\n",
        "\n",
        "STOPWORDS = set(stopwordlist)\n",
        "\n",
        "def removing_stopwords(text):\n",
        "  return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
        "\n",
        "dataset['text'] = dataset['text'].apply(lambda text: removing_stopwords(text))\n",
        "dataset['text'].tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP4S-kzQX8MS",
        "outputId": "1b06ae7e-92a3-44f3-9678-4dc6c9f09288"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95    rt @selek437: go. omicron spread even faster k...\n",
              "96    rt @merlinofcanada: 822 covid-19 patients hosp...\n",
              "97    #alberta plans end single-site order continuin...\n",
              "98    @don_coi @edmonton_wild @alexmunter @lindysmit...\n",
              "99    rt @abbedclosures: multiple dms over past 24 h...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing puncuation\n",
        "\n",
        "import string\n",
        "\n",
        "english_punctuation = string.punctuation\n",
        "punctuations_list = english_punctuation\n",
        "\n",
        "def removing_punctuation(text):\n",
        "  translator = str.maketrans('', '', punctuations_list)\n",
        "  return text.translate(translator)\n",
        "\n",
        "dataset['text'] = dataset['text'].apply(lambda text: removing_punctuation(text))\n",
        "dataset['text'].tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2ySr3KLYCRn",
        "outputId": "1dfa7112-a80f-4244-c1d8-44561149d856"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95    rt selek437 go omicron spread even faster kill...\n",
              "96    rt merlinofcanada 822 covid19 patients hospita...\n",
              "97    alberta plans end singlesite order continuingc...\n",
              "98    doncoi edmontonwild alexmunter lindysmithmd ch...\n",
              "99    rt abbedclosures multiple dms over past 24 hou...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing URLs\n",
        "\n",
        "def cleaning_URLs(data):\n",
        "    return re.sub('((www.[^s]+)|(https?://[^s]+))',' ',data)\n",
        "dataset['text'] = dataset['text'].apply(lambda x: cleaning_URLs(x))\n",
        "dataset['text'].tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_ZBvTbIYEkn",
        "outputId": "aca6b8e4-909c-4cf2-9452-35a551660494"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95    rt selek437 go omicron spread even faster kill...\n",
              "96    rt merlinofcanada 822 covid19 patients hospita...\n",
              "97    alberta plans end singlesite order continuingc...\n",
              "98    doncoi edmontonwild alexmunter lindysmithmd ch...\n",
              "99    rt abbedclosures multiple dms over past 24 hou...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing numbers\n",
        "\n",
        "def cleaning_numbers(data):\n",
        "    return re.sub('[0-9]+', '', data)\n",
        "dataset['text'] = dataset['text'].apply(lambda x: cleaning_numbers(x))\n",
        "dataset['text'].tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRZGnrczYFLQ",
        "outputId": "114e3f04-9583-4404-b541-cd4276ce0237"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95    rt selek go omicron spread even faster kill ol...\n",
              "96    rt merlinofcanada  covid patients hospital inc...\n",
              "97    alberta plans end singlesite order continuingc...\n",
              "98    doncoi edmontonwild alexmunter lindysmithmd ch...\n",
              "99    rt abbedclosures multiple dms over past  hours...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokensizing the text from tweets\n",
        "\n",
        "dataset['text'] = dataset['text'].apply(lambda x: x.split())\n",
        "dataset['text'].tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npnwzeoEYHNG",
        "outputId": "b7149578-7366-4afc-e16d-c2467b5372f7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95    [rt, selek, go, omicron, spread, even, faster,...\n",
              "96    [rt, merlinofcanada, covid, patients, hospital...\n",
              "97    [alberta, plans, end, singlesite, order, conti...\n",
              "98    [doncoi, edmontonwild, alexmunter, lindysmithm...\n",
              "99    [rt, abbedclosures, multiple, dms, over, past,...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming the data\n",
        "import nltk\n",
        "st = nltk.PorterStemmer()\n",
        "\n",
        "def stem_data(data):\n",
        "  text = [st.stem(word) for word in data]\n",
        "  return data\n",
        "\n",
        "dataset['text'] = dataset['text'].apply(lambda x: stem_data(x))\n",
        "dataset['text'].tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sONCHg8CYR87",
        "outputId": "316ee0dc-e021-4af7-b552-04d8527610a0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95    [rt, selek, go, omicron, spread, even, faster,...\n",
              "96    [rt, merlinofcanada, covid, patients, hospital...\n",
              "97    [alberta, plans, end, singlesite, order, conti...\n",
              "98    [doncoi, edmontonwild, alexmunter, lindysmithm...\n",
              "99    [rt, abbedclosures, multiple, dms, over, past,...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatizing the data\n",
        "nltk.download('wordnet')\n",
        "lm = nltk.WordNetLemmatizer()\n",
        "\n",
        "def lemm_data(data):\n",
        "  text = [lm.lemmatize(word) for word in data]\n",
        "  return data\n",
        "\n",
        "dataset['text'] = dataset['text'].apply(lambda x: lemm_data(x))\n",
        "dataset['text'].tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNtFP6RiYT2I",
        "outputId": "b892f6db-ecc8-4f62-ec36-dee0f16bbbc8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95    [rt, selek, go, omicron, spread, even, faster,...\n",
              "96    [rt, merlinofcanada, covid, patients, hospital...\n",
              "97    [alberta, plans, end, singlesite, order, conti...\n",
              "98    [doncoi, edmontonwild, alexmunter, lindysmithm...\n",
              "99    [rt, abbedclosures, multiple, dms, over, past,...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST CODE\n",
        "test = list(dataset['text'])\n",
        "len(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO6aADUmYV34",
        "outputId": "24067409-f767-47c2-e37d-741c5472382a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatonating the individual words into a single sentence\n",
        "\n",
        "\n",
        "for i in range(len(test)):\n",
        "  test[i] = \" \".join(test[i])\n",
        "\n",
        "dataset['cleantext'] = test\n",
        "dataset['cleantext'].tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ds4UY7BAYXsZ",
        "outputId": "524da584-2e9b-4000-9725-e8b217acaaae"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95    rt selek go omicron spread even faster kill ol...\n",
              "96    rt merlinofcanada covid patients hospital incr...\n",
              "97    alberta plans end singlesite order continuingc...\n",
              "98    doncoi edmontonwild alexmunter lindysmithmd ch...\n",
              "99    rt abbedclosures multiple dms over past hours ...\n",
              "Name: cleantext, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature extraction\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "bow_vectorizer = CountVectorizer(max_df=0.9, min_df=2, max_features=500000, stop_words='english')\n",
        "bow = bow_vectorizer.fit_transform(dataset['cleantext'])"
      ],
      "metadata": {
        "id": "G-xr-diGalrk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the city datasets on the trained models"
      ],
      "metadata": {
        "id": "0kCNoQuDZzkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading in trained logistic regression model\n",
        "import pickle\n",
        "\n",
        "model_logreg = pickle.load(open('trained_logistic_regression_model.sav', 'rb'))\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n"
      ],
      "metadata": {
        "id": "2Qi-7gi9Z2d_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to time constraints, could not complete the code."
      ],
      "metadata": {
        "id": "aBW7zeB2de0t"
      }
    }
  ]
}